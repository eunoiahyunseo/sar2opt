import torch
import os
from PIL import Image
import torch.nn as nn
from peft import LoraConfig, get_peft_model
from torchvision.transforms import v2
import torch.nn.functional as F
import warnings
from utils.transforms import make_transform
from configilm.extra.DataSets import BENv2_DataSet

# [NEW] ìƒˆë¡œ ì¶”ê°€ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬
from torch.utils.data import DataLoader, Dataset # Dataset ì¶”ê°€
from sklearn.metrics import multilabel_confusion_matrix, classification_report
from tqdm import tqdm
import numpy as np
import glob # [NEW] SEN1-2 íŒŒì¼ ê²€ìƒ‰ì„ ìœ„í•´ ì¶”ê°€

# [NEW] GMM í”¼íŒ… ë° ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans # [NEW] K-Means ì„í¬íŠ¸
from scipy.stats import norm

# -----------------------------------------------------------------
# ì„¤ì •ê°’ (ê¸°ì¡´ê³¼ ë™ì¼ + SEN1-2 ê²½ë¡œ ì¶”ê°€)
# -----------------------------------------------------------------
DATA_TYPE = "sar"
INFERENCE_CHECKPOINT_PATH = f"./checkpoints/stage0_{DATA_TYPE}/checkpoint_stage0_epoch101.pth"

SEN12_ROOT_DIR = "/home/hyunseo/workspace/sar2opt/dataset/v_2"

NORM_MEAN = (0.485, 0.456, 0.406)
NORM_STD = (0.229, 0.224, 0.225)

LABEL_SIZE = 19
REPO_NAME = "/home/hyunseo/workspace/dinov3"
LORA_RANK = 8
LORA_ALPHA = 16
LORA_DROPOUT = 0.05
LORA_TARGET_MODULES = ["qkv"]
MERGE_PATCH = False
RESIZE_SIZE = 256 if MERGE_PATCH else 128
# DATA_TYPE = "opt" # ì´ ë³€ìˆ˜ëŠ” ì´ì œ evaluate_dataset í•¨ìˆ˜ë¡œ ì´ë™
BATCH_SIZE = 112 
SAVE_FIG_FOLDER = "./save_fig"

class SEN12_Dataset(Dataset):
    """
    SEN1-2 ë°ì´í„°ì…‹ì„ ìœ„í•œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ (ë ˆì´ë¸” ì—†ìŒ)
    [ìˆ˜ì •ë¨] s1(SAR)ê³¼ s2(OPT) ì´ë¯¸ì§€ë¥¼ ì •ë ¬(sort)í•˜ì—¬ ìŒìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    [ìˆ˜ì •ë¨] 256x256 ì´ë¯¸ì§€ë¥¼ 4ê°œì˜ 128x128 íŒ¨ì¹˜ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    [ìˆ˜ì •ë¨] 'sar', 'opt' í‚¤ë¥¼ ê°€ì§„ transform ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    def __init__(self, root_dir, transform: dict = None):
        """
        :param root_dir: ë°ì´í„°ì…‹ì˜ ìµœìƒìœ„ ê²½ë¡œ (ì˜ˆ: 'v_2/')
        :param transform: {"sar": sar_transform, "opt": opt_transform} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        self.root_dir = root_dir
        self.transform_dict = transform 
        
        self.sar_image_paths = []
        self.opt_image_paths = []
        extensions = ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']

        # [ìˆ˜ì •ë¨] 'agri', 'urban' ë“± í•˜ìœ„ í´ë˜ìŠ¤ í´ë”ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        try:
            class_dirs = [d for d in glob.glob(os.path.join(self.root_dir, '*')) if os.path.isdir(d)]
            if not class_dirs:
                print(f"Warning: No class directories (like 'agri', 'urban') found in {self.root_dir}")
                # root_dir ìì²´ê°€ í´ë˜ìŠ¤ í´ë”ë¥¼ í¬í•¨í•˜ëŠ” ê²½ë¡œì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¬ì‹œë„
                class_dirs = [self.root_dir] 
        except Exception as e:
            print(f"Error finding class dirs: {e}")
            class_dirs = [self.root_dir] # fallback

        # [ìˆ˜ì •ë¨] ê° í´ë˜ìŠ¤ í´ë” ë‚´ì—ì„œ s1/s2 í˜ì–´ë§ ìˆ˜í–‰
        for class_dir in class_dirs:
            s1_dir = os.path.join(class_dir, 's1')
            s2_dir = os.path.join(class_dir, 's2')

            s1_paths_for_class = []
            s2_paths_for_class = []

            for ext in extensions:
                s1_paths_for_class.extend(glob.glob(os.path.join(s1_dir, f'*{ext}')))
                s2_paths_for_class.extend(glob.glob(os.path.join(s2_dir, f'*{ext}')))
            
            # --- [í•µì‹¬] ì •ë ¬(sort) ê¸°ë°˜ í˜ì–´ë§ ---
            s1_paths_for_class.sort()
            s2_paths_for_class.sort()
            
            # s1ê³¼ s2ì˜ ì´ë¯¸ì§€ ê°œìˆ˜ê°€ ë‹¤ë¥´ë©´, í•´ë‹¹ í´ë˜ìŠ¤ëŠ” ê²½ê³  í›„ ê±´ë„ˆëœë‹ˆë‹¤.
            if len(s1_paths_for_class) != len(s2_paths_for_class):
                print(f"Warning: Mismatch in class '{os.path.basename(class_dir)}'.")
                print(f"  Found {len(s1_paths_for_class)} s1 images but {len(s2_paths_for_class)} s2 images. Skipping this class.")
                continue
                
            # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë©”ì¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            self.sar_image_paths.extend(s1_paths_for_class)
            self.opt_image_paths.extend(s2_paths_for_class)
        
        if not self.sar_image_paths:
            print(f"Error: No valid s1/s2 pairs were found in {root_dir}")
        
        self.patches_per_image = 4

    def __len__(self):
        # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ëŠ” (ì°¾ì•„ë‚¸ ìŒ(pair)ì˜ ìˆ˜ * 4)
        return len(self.sar_image_paths) * self.patches_per_image

    def __getitem__(self, idx):
        # 1. ì–´ë–¤ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí• ì§€ ê³„ì‚°
        image_index = idx // self.patches_per_image
        
        # 2. í•´ë‹¹ ì´ë¯¸ì§€ì—ì„œ ëª‡ ë²ˆì§¸ íŒ¨ì¹˜(0, 1, 2, 3)ë¥¼ ìë¥¼ì§€ ê³„ì‚°
        patch_index = idx % self.patches_per_image

        # 3. [ìˆ˜ì •ë¨] ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ SAR (s1)ê³¼ OPT (s2) ê²½ë¡œë¥¼ ì§ì ‘ ê°€ì ¸ì˜´
        sar_img_path = self.sar_image_paths[image_index]
        opt_img_path = self.opt_image_paths[image_index]
        
        try:
            # 4. ì›ë³¸ 256x256 ì´ë¯¸ì§€ ìŒ(pair) ë¡œë“œ
            sar_image_raw = Image.open(sar_img_path).convert("L")
            sar_image_raw = Image.merge("RGB", (sar_image_raw, sar_image_raw, sar_image_raw))
            
            opt_image_raw = Image.open(opt_img_path).convert("RGB")
            
        except Exception as e:
            print(f"Error loading image pair at index {image_index}: {e}")
            print(f"  SAR: {sar_img_path}")
            print(f"  OPT: {opt_img_path}")
            return None # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜ (DataLoaderì—ì„œ ì²˜ë¦¬ í•„ìš”)

        # 5. patch_indexì— ë”°ë¼ 128x128 ì˜ì—­ ìë¥´ê¸° (ë¡œì§ ë™ì¼)
        if patch_index == 0:    # Top-Left (TL)
            box = (0, 0, 128, 128)
        elif patch_index == 1:  # Top-Right (TR)
            box = (128, 0, 256, 128)
        elif patch_index == 2:  # Bottom-Left (BL)
            box = (0, 128, 128, 256)
        else: # patch_index == 3   # Bottom-Right (BR)
            box = (128, 128, 256, 256)
            
        sar_patch = sar_image_raw.crop(box)
        opt_patch = opt_image_raw.crop(box)
        
        # 6. 128x128 íŒ¨ì¹˜ì— ë”•ì…”ë„ˆë¦¬ì˜ transform ì ìš© (ë¡œì§ ë™ì¼)
        sar_tensor = sar_patch
        opt_tensor = opt_patch

        if self.transform_dict is not None:
            if 'sar' in self.transform_dict and self.transform_dict['sar'] is not None:
                sar_tensor = self.transform_dict['sar'](sar_patch)
            if 'opt' in self.transform_dict and self.transform_dict['opt'] is not None:
                opt_tensor = self.transform_dict['opt'](opt_patch)
        
        # 7. ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ (ë¡œì§ ë™ì¼)
        return {"sar": sar_tensor, "opt": opt_tensor}
    
class DinoV3Linear(nn.Module):
    def __init__(self, backbone, hidden_size: int, num_classes: int, freeze_backbone: bool = True):
        # ... (ë‚´ìš© ë™ì¼) ...
        super().__init__()
        self.backbone = backbone
        if freeze_backbone:
            for p in self.backbone.parameters():
                p.requires_grad = False
            self.backbone.eval()
        self.head = nn.Linear(hidden_size, num_classes)

    def forward_features(self, pixel_values):
        return self.backbone(pixel_values)

    def forward(self, pixel_values):
        outputs = self.backbone(pixel_values)
        logits = self.head(outputs)
        return logits

def evaluate_dataset(model, data_loader, device, dataset_name, data_type, has_labels = False, label_size = None):
    """
    ì£¼ì–´ì§„ ë°ì´í„°ë¡œë”ì— ëŒ€í•´ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  GMM í”Œë¡¯ì„ ìƒì„±í•©ë‹ˆë‹¤.
    [ìˆ˜ì •] GMMì„ 0.5 ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´(piecewise) í”¼íŒ…í•©ë‹ˆë‹¤.
    """
    
    all_labels = []
    all_preds = []
    all_probs = []

    print(f"\n--- ğŸš€ Starting batch inference on {dataset_name} ({data_type}) data ---")

    with torch.inference_mode():
        # ... (Tqdm ë£¨í”„ ... ë™ì¼) ...
        for batch in tqdm(data_loader, desc=f"Evaluating {dataset_name}"):
            
            if batch is None:
                continue

            if has_labels:
                img, lbl = batch
                inputs = img[data_type].to(device)
                labels = lbl.to(device)
            else:
                img_tensor_dict = batch 
                inputs = img_tensor_dict[data_type].to(device)

            logits = model(inputs)
            probabilities = torch.sigmoid(logits)
            
            all_probs.append(probabilities.cpu())

            if has_labels:
                threshold = 0.5
                preds = (probabilities > threshold).int()
                all_labels.append(labels.cpu())
                all_preds.append(preds.cpu())

            break

    print(f"Inference complete for {dataset_name}.")
    
    if len(all_probs) == 0:
        print(f"Error: No data processed for {dataset_name}. Skipping GMM.")
        return None
        
    all_probs = torch.cat(all_probs, dim=0).numpy()

    if has_labels:
        # --- Metrics ê³„ì‚° (BENv2) ---
        # ... (Metrics ì½”ë“œ ... ë™ì¼) ...
        all_labels = torch.cat(all_labels, dim=0).numpy()
        all_preds = torch.cat(all_preds, dim=0).numpy()
        
        print(f"\n--- ğŸ“Š Multi-Label Confusion Matrix ({dataset_name}) ---")
        mcm = multilabel_confusion_matrix(all_labels, all_preds)
        print(mcm)
        
        print(f"\n--- ğŸ“‹ Classification Report ({dataset_name}) ---")
        report = classification_report(
            all_labels, 
            all_preds, 
            target_names=[f"Class {i:02d}" for i in range(label_size)], 
            zero_division=0
        )
        print(report)
    else:
        print(f"\n--- ğŸ“Š Metrics skipped for {dataset_name} (no labels provided) ---")


    # [NEW] --- 0.5 ê¸°ì¤€ Piecewise GMM í”¼íŒ… ---
    print(f"\n--- ğŸ“ˆ Fitting Piecewise GMM (split at z=0.5) ---")
    
    flat_probs = all_probs.flatten()
    
    # 1. ë°ì´í„°ë¥¼ 0.5 ê¸°ì¤€ìœ¼ë¡œ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• 
    data_neg = flat_probs[flat_probs < 0.5].reshape(-1, 1)
    data_pos = flat_probs[flat_probs >= 0.5].reshape(-1, 1)

    # 2. ê° ê·¸ë£¹ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
    if data_neg.size == 0:
        print("Error: No data found for Negative Component (z < 0.5).")
        return None
    if data_pos.size == 0:
        print("Error: No data found for Positive Component (z >= 0.5).")
        return None
        
    print(f"Fitting GMM 1 to {len(data_neg)} points (< 0.5)")
    print(f"Fitting GMM 2 to {len(data_pos)} points (>= 0.5)")

    # 3. ê° ê·¸ë£¹ì— n_components=1 GMMì„ ê°œë³„ì ìœ¼ë¡œ í”¼íŒ…
    gmm_neg = GaussianMixture(n_components=1, random_state=42, n_init=10)
    gmm_neg.fit(data_neg)
    
    gmm_pos = GaussianMixture(n_components=1, random_state=42, n_init=10)
    gmm_pos.fit(data_pos)

    # 4. ê° GMMì—ì„œ íŒŒë¼ë¯¸í„° ë° ê°€ì¤‘ì¹˜(weight) ì¶”ì¶œ
    mean_neg = gmm_neg.means_.item()
    std_neg = np.sqrt(gmm_neg.covariances_.item())
    weight_neg = len(data_neg) / len(flat_probs) # ì „ì²´ ë°ì´í„° ì¤‘ ì´ ê·¸ë£¹ì˜ ë¹„ìœ¨
    
    mean_pos = gmm_pos.means_.item()
    std_pos = np.sqrt(gmm_pos.covariances_.item())
    weight_pos = len(data_pos) / len(flat_probs) # ì „ì²´ ë°ì´í„° ì¤‘ ì´ ê·¸ë£¹ì˜ ë¹„ìœ¨

    print(f"GMM fitted successfully (piecewise).")
    print(f"  - Negative Component (z < 0.5): Mean={mean_neg:.4f}, Weight={weight_neg:.4f}")
    print(f"  - Positive Component (z >= 0.5): Mean={mean_pos:.4f}, Weight={weight_pos:.4f}")

    # 3. ì‹œê°í™” (ê°œë³„ í”Œë¡¯)
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(12, 7))
    # íˆìŠ¤í† ê·¸ë¨ì€ â˜…ì „ì²´ ì›ë³¸â˜… ë°ì´í„°ë¡œ ê·¸ë ¤ì•¼ í•©ë‹ˆë‹¤.
    plt.hist(flat_probs, bins=100, density=True, color='lightgray', alpha=0.8, label='Predicted Probability Frequency')

    x_plot = np.linspace(0, 1, 1000).ravel()
    
    # ê° ì»´í¬ë„ŒíŠ¸ì˜ PDFë¥¼ ê°€ì¤‘ì¹˜(weight)ì™€ í•¨ê»˜ ê³„ì‚°
    pdf_neg_weighted = weight_neg * norm.pdf(x_plot, loc=mean_neg, scale=std_neg)
    pdf_pos_weighted = weight_pos * norm.pdf(x_plot, loc=mean_pos, scale=std_pos)
    
    # [ìˆ˜ì •] ë‘ ê°œì˜ ê°œë³„ PDFë¥¼ í•©ì³ ì „ì²´ Mixtureë¥¼ ë§Œë“­ë‹ˆë‹¤.
    pdf_total = pdf_neg_weighted + pdf_pos_weighted 
    
    plt.plot(x_plot, pdf_total, color='black', lw=2.5, label='Fitted GMM (Mixture, Piecewise)')
    
    plt.plot(x_plot, pdf_pos_weighted, color='crimson', linestyle='--', lw=3,
             label=f'Positive Component (Î¼={mean_pos:.2f})')
    
    plt.plot(x_plot, pdf_neg_weighted, color='royalblue', linestyle='--', lw=2, 
             label=f'Negative Component (Î¼={mean_neg:.2f})')
    
    # [ìˆ˜ì •] ì œëª©ê³¼ íŒŒì¼ëª… ë³€ê²½
    plt.title(f'Distribution for {dataset_name} (Fitted GMM, Piecewise 0.5 Split)', fontsize=16, weight='bold')
    plt.xlabel('Predicted Probability (z)', fontsize=12)
    plt.ylabel('Density', fontsize=12)
    plt.legend(loc='best', fontsize=11)
    plt.xlim(0, 1)
    plt.ylim(bottom=0)
    
    save_filename = os.path.join(SAVE_FIG_FOLDER, f"predicted_probability_{dataset_name}_gmm_fit_piecewise.png")
    plt.savefig(save_filename, dpi=300)
    print(f"\nSaved the plot as '{save_filename}'")
    plt.close() # ê·¸ë˜í”„ ì°½ì„ ë‹«ì•„ ë‹¤ìŒ í”Œë¡¯ì— ì˜í–¥ì´ ì—†ë„ë¡ í•¨

    # [ìˆ˜ì •] GMM íŒŒë¼ë¯¸í„° ë°˜í™˜
    return {'mean_neg': mean_neg, 'std_neg': std_neg, 'mean_pos': mean_pos, 'std_pos': std_pos}
# -----------------------------------------------------------------
# [NEW] ë¹„êµ í”Œë¡¯ì„ ê·¸ë¦¬ëŠ” í—¬í¼ í•¨ìˆ˜
# -----------------------------------------------------------------
def plot_comparison_pdfs(benv2_params, sen12_params):
    """
    BENv2ì™€ SEN12ì˜ GMM ì»´í¬ë„ŒíŠ¸ë¥¼ ê°€ì¤‘ì¹˜(phi) ì—†ì´ ë¹„êµí•˜ëŠ” í”Œë¡¯ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("\n--- ğŸ“Š Plotting Comparison of Unweighted GMM Components (phi-ì—†ì´) ---")
    x_plot = np.linspace(0, 1, 1000).ravel()
    
    # --- í”Œë¡¯ 1: Negative Components (Comp 1) ---
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(12, 7))
    
    # BENv2 Negative PDF (phi-ì—†ì´)
    pdf_neg_benv2 = norm.pdf(x_plot, loc=benv2_params['mean_neg'], scale=benv2_params['std_neg'])
    plt.plot(x_plot, pdf_neg_benv2, color='blue', linestyle='--', lw=2, 
             label=f"BENv2 Negative (Î¼={benv2_params['mean_neg']:.2f}, Ïƒ={benv2_params['std_neg']:.2f})")

    # SEN12 Negative PDF (phi-ì—†ì´)
    pdf_neg_sen12 = norm.pdf(x_plot, loc=sen12_params['mean_neg'], scale=sen12_params['std_neg'])
    plt.plot(x_plot, pdf_neg_sen12, color='cyan', linestyle='-', lw=2, 
             label=f"SEN12 Negative (Î¼={sen12_params['mean_neg']:.2f}, Ïƒ={sen12_params['std_neg']:.2f})")
    
    plt.title('Comparison of Negative Components (Unweighted, phi-ì—†ì´)', fontsize=16, weight='bold')
    plt.xlabel('Predicted Probability (z)', fontsize=12)
    plt.ylabel('Density (Unweighted)', fontsize=12)
    plt.legend(loc='best', fontsize=11)
    plt.xlim(0, 1)
    plt.ylim(bottom=0)
    save_filename = os.path.join(SAVE_FIG_FOLDER, "comparison_negative_components.png")
    plt.savefig(save_filename, dpi=300)
    plt.close()
    print(f"Saved '{save_filename}'")

    # --- í”Œë¡¯ 2: Positive Components (Comp 2) ---
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(12, 7))

    # BENv2 Positive PDF (phi-ì—†ì´)
    if benv2_params['std_pos'] > 0: # Check if it was fitted
        pdf_pos_benv2 = norm.pdf(x_plot, loc=benv2_params['mean_pos'], scale=benv2_params['std_pos'])
        plt.plot(x_plot, pdf_pos_benv2, color='red', linestyle='--', lw=2, 
                 label=f"BENv2 Positive (Î¼={benv2_params['mean_pos']:.2f}, Ïƒ={benv2_params['std_pos']:.2f})")

    # SEN12 Positive PDF (phi-ì—†ì´)
    if sen12_params['std_pos'] > 0: # Check if it was fitted
        pdf_pos_sen12 = norm.pdf(x_plot, loc=sen12_params['mean_pos'], scale=sen12_params['std_pos'])
        plt.plot(x_plot, pdf_pos_sen12, color='orange', linestyle='-', lw=2, 
                 label=f"SEN12 Positive (Î¼={sen12_params['mean_pos']:.2f}, Ïƒ={sen12_params['std_pos']:.2f})")

    plt.title('Comparison of Positive Components (Unweighted, phi-ì—†ì´)', fontsize=16, weight='bold')
    plt.xlabel('Predicted Probability (z)', fontsize=12)
    plt.ylabel('Density (Unweighted)', fontsize=12)
    plt.legend(loc='best', fontsize=11)
    plt.xlim(0, 1)
    plt.ylim(bottom=0)
    save_filename = os.path.join(SAVE_FIG_FOLDER, "comparison_positive_components.png")
    plt.savefig(save_filename, dpi=300)
    plt.close()
    print(f"Saved '{save_filename}'")


# -----------------------------------------------------------------
# [ìˆ˜ì •ë¨] BENv2 ì£¼ì„ í•´ì œ ë° ë¹„êµ í”Œë¡¯ í˜¸ì¶œ
# -----------------------------------------------------------------
def run_inference():

    # --- ê³µí†µ ë³€í™˜ ì •ì˜ ---
    transform_opt_val = make_transform(resize_size=RESIZE_SIZE, data_type="opt", dataset = "benv2", is_train=False)
    transform_sar_val = make_transform(resize_size=RESIZE_SIZE, data_type="sar", dataset = "benv2", is_train=False)

    transform_sar_sen12_val = make_transform(resize_size=RESIZE_SIZE, data_type="sar", dataset = "sen12", is_train=False)
    transform_opt_sen12_val = make_transform(resize_size=RESIZE_SIZE, data_type="opt", dataset = "sen12", is_train=False)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # --- ëª¨ë¸ ë¡œë“œ (ê³µí†µ) ---
    print("--- Loading Model ---")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        cls_feature_size = torch.hub.load(REPO_NAME, 'dinov3_vith16plus', source='local').num_features
        backbone = torch.hub.load(REPO_NAME, 'dinov3_vith16plus', source='local')

    lora_config = LoraConfig(
        r=LORA_RANK, lora_alpha=LORA_ALPHA, target_modules=LORA_TARGET_MODULES,
        lora_dropout=LORA_DROPOUT, bias="none",
    )
    
    model = DinoV3Linear(backbone, hidden_size=cls_feature_size, num_classes=LABEL_SIZE, freeze_backbone=True)
    model = get_peft_model(model, lora_config)
    
    try:
        checkpoint = torch.load(INFERENCE_CHECKPOINT_PATH, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()
        print(f"Successfully loaded model weights from epoch {checkpoint.get('epoch', 'N/A')}")
    except Exception as e:
        print(f"Error loading model state_dict: {e}")
        try:
            from collections import OrderedDict
            new_state_dict = OrderedDict()
            for k, v in checkpoint['model_state_dict'].items():
                name = k[7:] if k.startswith('module.') else k
                new_state_dict[name] = v
            model.load_state_dict(new_state_dict)
            model.to(device)
            model.eval()
            print("Successfully loaded model weights (after stripping 'module.' prefix).")
        except Exception as e_retry:
            print(f"Failed to load checkpoint even after retry: {e_retry}")
            return
            
    print("-" * 40)

    # --- 1. BENv2 í‰ê°€ (ë ˆì´ë¸” ìˆìŒ) ---
    print("--- 1. Preparing BENv2 (Validation Set) ---")
    
    # [ìˆ˜ì •] BENv2 í‰ê°€ ì£¼ì„ í•´ì œ
    datapath = {
        "images_lmdb": "/home/hyunseo/workspace/rico-hdl/Encoded-BigEarthNet",
        "metadata_parquet": "/home/hyunseo/workspace/sar2opt/dataset/BigEarthNetv2/metadata.parquet",
        "metadata_snow_cloud_parquet": "/home/hyunseo/workspace/sar2opt/dataset/BigEarthNetv2/metadata_for_patches_with_snow_cloud_or_shadow.parquet",
    }
    ds_benv2 = BENv2_DataSet.BENv2DataSet(
        data_dirs=datapath,
        img_size=(12, 120, 120),
        split='test',
        transform={"opt": transform_opt_val, "sar": transform_sar_val}, # ê°œë³„ ë³€í™˜ ì „ë‹¬
        merge_patch=False,
        max_len=5000, # SEN12ì™€ ìƒ˜í”Œ ìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ 5000ê°œë¡œ ì œí•œ (ì˜µì…˜)
    )

    loader_benv2 = DataLoader(
        ds_benv2, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True
    )

    print(f"Loaded {len(ds_benv2)} BENv2 test images.")
    
    # [í˜¸ì¶œ 1] BENv2 í‰ê°€ ì‹¤í–‰ (opt ëª¨ë¸, ë ˆì´ë¸” ìˆìŒ)
    # [ìˆ˜ì •] GMM íŒŒë¼ë¯¸í„° ë°˜í™˜ ë°›ê¸°
    benv2_params = evaluate_dataset(model, loader_benv2, device, 
                                    dataset_name="BENv2", 
                                    data_type=DATA_TYPE,
                                    has_labels=True, 
                                    label_size=LABEL_SIZE)

    print("-" * 40)
    
    # --- 2. SEN1-2 í‰ê°€ (ë ˆì´ë¸” ì—†ìŒ) ---
    print("--- 2. Preparing SEN1-2 (Unlabeled Set) ---")
    sen12_params = None # [NEW] íŒŒë¼ë¯¸í„° ë³€ìˆ˜ ì´ˆê¸°í™”
    if not os.path.exists(SEN12_ROOT_DIR):
        print(f"Warning: SEN12_ROOT_DIR '{SEN12_ROOT_DIR}' not found. Skipping SEN1-2 evaluation.")
    else:
        ds_sen12_full = SEN12_Dataset(
            root_dir=SEN12_ROOT_DIR,
            transform={"opt": transform_opt_sen12_val, "sar": transform_sar_sen12_val} 
        )

        VAL_SPLIT_RATIO = 0.1
        total_size = len(ds_sen12_full)
        val_size = int(total_size * VAL_SPLIT_RATIO)
        train_size = total_size - val_size
        
        print(f"Splitting SEN1-2 full dataset ({total_size} patches) into:")
        print(f"  - Train: {train_size} patches")
        print(f"  - Val:   {val_size} patches")

        generator = torch.Generator().manual_seed(42)
        ds_sen12_train, ds_sen12_val = torch.utils.data.random_split(
            ds_sen12_full, 
            [train_size, val_size],
            generator=generator
        )

        loader_sen12_val = DataLoader(
            ds_sen12_val, 
            batch_size=BATCH_SIZE, 
            shuffle=False, 
            num_workers=4, 
            pin_memory=True
        )

        print(f"Loaded {len(loader_sen12_val)} SEN1-2 val patches.")
        

        sen12_params = evaluate_dataset(model, loader_sen12_val, device, 
                                        dataset_name="SEN12_Val", 
                                        data_type=DATA_TYPE,
                                        has_labels=False)

    print("-" * 40)
    
    # --- 3. [NEW] ë¹„êµ í”Œë¡¯ ìƒì„± ---
    if benv2_params and sen12_params:
        plot_comparison_pdfs(benv2_params, sen12_params)
    else:
        print("Skipping comparison plots because one or both dataset evaluations failed.")


if __name__ == "__main__":
    run_inference()